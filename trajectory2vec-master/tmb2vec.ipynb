{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import pickle as cPickle\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import *\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "random.seed(2016)\n",
    "sampleNum = 10\n",
    "\n",
    "def completeTrajectories():\n",
    "    simTrjss = cPickle.load(open('./simulated_data/sim_trajectories','rb'))\n",
    "    simTrjComps = []\n",
    "    for simTrjs in simTrjss:\n",
    "        trjsCom = []\n",
    "        for i in range(0,len(simTrjs)):\n",
    "            rec = []\n",
    "            if i==0:\n",
    "                # time, locationC, speedC, rotC\n",
    "                rec = [0,0,0,0]\n",
    "            else:\n",
    "                locC = math.sqrt((simTrjs[i][1]-simTrjs[i-1][1])**2+(simTrjs[i][2]-simTrjs[i-1][2])**2)\n",
    "                rec.append(simTrjs[i][0])\n",
    "                rec.append(locC)\n",
    "                rec.append(locC/(simTrjs[i][0]-simTrjs[i-1][0]))\n",
    "                rec.append(math.atan((simTrjs[i][2]-simTrjs[i-1][2])/ (simTrjs[i][1]-simTrjs[i-1][1])))\n",
    "            trjsCom.append(rec)\n",
    "        simTrjComps.append(trjsCom)\n",
    "    cPickle.dump(simTrjComps,open('./simulated_data/sim_trajectories_complete','wb'))\n",
    "    return simTrjComps\n",
    "\n",
    "def computeFeas():\n",
    "    simTrjCompss = cPickle.load(open('./simulated_data/sim_trajectories_complete','rb'))\n",
    "    simTrjFeas = []\n",
    "    for simTrjComps in simTrjCompss:\n",
    "        trjsComfea = []\n",
    "        for i in range(0,len(simTrjComps)):\n",
    "            rec = []\n",
    "            if i==0:\n",
    "                # time, locationC, speedC, rotC\n",
    "                rec = [0,0,0,0]\n",
    "            else:\n",
    "                locC = simTrjComps[i][1]\n",
    "                locCrate = locC/(simTrjComps[i][0]-simTrjComps[i-1][0])\n",
    "                rec.append(simTrjComps[i][0])\n",
    "                rec.append(locCrate)\n",
    "                if locCrate<3:\n",
    "                    rec.append(0)\n",
    "                    rec.append(0)\n",
    "                else:\n",
    "                    rec.append(simTrjComps[i][2]-simTrjComps[i-1][2])\n",
    "                    rec.append(simTrjComps[i][3]-simTrjComps[i-1][3])\n",
    "            trjsComfea.append(rec)\n",
    "        simTrjFeas.append(trjsComfea)\n",
    "    cPickle.dump(simTrjFeas, open('./simulated_data/sim_trajectories_feas', 'wb'))\n",
    "    return simTrjFeas\n",
    "\n",
    "def rolling_window(sample, windowsize = 600, offset = 300):\n",
    "    timeLength = sample[len(sample)-1][0]\n",
    "    windowLength = int (timeLength/offset)+1\n",
    "    windows = []\n",
    "    for i in range(0,windowLength):\n",
    "        windows.append([])\n",
    "\n",
    "    for record in sample:\n",
    "        time = record[0]\n",
    "        for i in range(0,windowLength):\n",
    "            if (time>(i*offset)) & (time<(i*offset+windowsize)):\n",
    "                windows[i].append(record)\n",
    "    return windows\n",
    "    # pass\n",
    "\n",
    "def behavior_ext(windows):\n",
    "    behavior_sequence = []\n",
    "    for window in windows:\n",
    "        behaviorFeature = []\n",
    "        records = np.array(window)\n",
    "        if len(records) != 0:\n",
    "            # print np.shape(records)\n",
    "            pd = pandas.DataFrame(records)\n",
    "            pdd =  pd.describe()\n",
    "            # print pdd[1][0]\n",
    "            # for ii in range(1,4):\n",
    "            #     for jj in range(1,8):\n",
    "            #         behaviorFeature.append(pdd[ii][jj])\n",
    "            # behaviorFeature.append(pdd[0][1])\n",
    "            behaviorFeature.append(pdd[1][1])\n",
    "            behaviorFeature.append(pdd[2][1])\n",
    "            behaviorFeature.append(pdd[3][1])\n",
    "            # behaviorFeature.append(pdd[0][2])\n",
    "            # behaviorFeature.append(pdd[1][2])\n",
    "            # behaviorFeature.append(pdd[2][2])\n",
    "            # behaviorFeature.append(pdd[3][2])\n",
    "            # behaviorFeature.append(pdd[0][3])\n",
    "            behaviorFeature.append(pdd[1][3])\n",
    "            behaviorFeature.append(pdd[2][3])\n",
    "            behaviorFeature.append(pdd[3][3])\n",
    "            # behaviorFeature.append(pdd[0][4])\n",
    "            behaviorFeature.append(pdd[1][4])\n",
    "            behaviorFeature.append(pdd[2][4])\n",
    "            behaviorFeature.append(pdd[3][4])\n",
    "            # behaviorFeature.append(pdd[0][5])\n",
    "            behaviorFeature.append(pdd[1][5])\n",
    "            behaviorFeature.append(pdd[2][5])\n",
    "            behaviorFeature.append(pdd[3][5])\n",
    "            # behaviorFeature.append(pdd[0][6])\n",
    "            behaviorFeature.append(pdd[1][6])\n",
    "            behaviorFeature.append(pdd[2][6])\n",
    "            behaviorFeature.append(pdd[3][6])\n",
    "            # behaviorFeature.append(pdd[0][7])\n",
    "            behaviorFeature.append(pdd[1][7])\n",
    "            behaviorFeature.append(pdd[2][7])\n",
    "            behaviorFeature.append(pdd[3][7])\n",
    "\n",
    "            behavior_sequence.append(behaviorFeature)\n",
    "    return behavior_sequence\n",
    "\n",
    "def generate_behavior_sequences():\n",
    "    f = open('./simulated_data/sim_trajectories_feas','rb')\n",
    "    sim_data = cPickle.load(f)\n",
    "    behavior_sequences = []\n",
    "\n",
    "    for sample in sim_data:\n",
    "        windows = rolling_window(sample)\n",
    "        behavior_sequence = behavior_ext(windows)\n",
    "        print(len(behavior_sequence))\n",
    "        behavior_sequences.append(behavior_sequence)\n",
    "    fout = open('./simulated_data/sim_behavior_sequences','wb')\n",
    "    cPickle.dump(behavior_sequences,fout)\n",
    "\n",
    "def generate_normal_behavior_sequence():\n",
    "    f = open('./simulated_data/sim_behavior_sequences','rb')\n",
    "    behavior_sequences = cPickle.load(f)\n",
    "\n",
    "    print(np.shape(behavior_sequences))\n",
    "    behavior_sequences_normal = []\n",
    "    templist = []\n",
    "    for item in behavior_sequences:\n",
    "        for ii in item:\n",
    "            templist.append(ii)\n",
    "        print (len(item))\n",
    "    print(len(templist))\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    # print np.shape(behavior_sequence)\n",
    "    templist_normal = min_max_scaler.fit_transform(templist).tolist()\n",
    "    index = 0\n",
    "    for item in behavior_sequences:\n",
    "        behavior_sequence_normal = []\n",
    "        for ii in item:\n",
    "            behavior_sequence_normal.append(templist_normal[index])\n",
    "            index = index + 1\n",
    "        print(len(behavior_sequence_normal))\n",
    "        behavior_sequences_normal.append(behavior_sequence_normal)\n",
    "    print(index)\n",
    "    print(np.shape(behavior_sequences_normal))\n",
    "    fout = open('./simulated_data/sim_normal_behavior_sequences', 'wb')\n",
    "    cPickle.dump(behavior_sequences_normal, fout)\n",
    "\n",
    "def trajectory2Vec():\n",
    "    def loopf(prev, i):\n",
    "        return prev\n",
    "\n",
    "    # Parameters\n",
    "    learning_rate = 0.0001\n",
    "    training_epochs = 300\n",
    "    display_step = 100\n",
    "\n",
    "    # Network Parameters\n",
    "    # the size of the hidden state for the lstm (notice the lstm uses 2x of this amount so actually lstm will have state of size 2)\n",
    "    size = 100\n",
    "    # 2 different sequences total\n",
    "    batch_size = 1\n",
    "    # the maximum steps for both sequences is 5\n",
    "    max_n_steps = 17\n",
    "    # each element/frame of the sequence has dimension of 3\n",
    "    frame_dim = 18\n",
    "\n",
    "    input_length = tf.placeholder(tf.int32)\n",
    "\n",
    "    initializer = tf.random_uniform_initializer(-1, 1)\n",
    "\n",
    "    # the sequences, has n steps of maximum size\n",
    "    # seq_input = tf.placeholder(tf.float32, [batch_size, max_n_steps, frame_dim])\n",
    "    seq_input = tf.placeholder(tf.float32, [max_n_steps, batch_size, frame_dim])\n",
    "    # what timesteps we want to stop at, notice it's different for each batch hence dimension of [batch]\n",
    "\n",
    "    # inputs for rnn needs to be a list, each item/frame being a timestep.\n",
    "    # we need to split our input into each timestep, and reshape it because split keeps dims by default\n",
    "\n",
    "    useful_input = seq_input[0:input_length[0]]\n",
    "    loss_inputs = [tf.reshape(useful_input, [-1])]\n",
    "    encoder_inputs = [item for item in tf.unstack(seq_input)]\n",
    "    # if encoder input is \"X, Y, Z\", then decoder input is \"0, X, Y, Z\". Therefore, the decoder size\n",
    "    # and target size equal encoder size plus 1. For simplicity, here I droped the last one.\n",
    "    decoder_inputs = ([tf.zeros_like(encoder_inputs[0], name=\"GO\")] + encoder_inputs[:-1])\n",
    "    targets = encoder_inputs\n",
    "\n",
    "    # basic LSTM seq2seq model\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(size, state_is_tuple=True, use_peepholes=True)\n",
    "    _, enc_state = tf.contrib.rnn.static_rnn(cell, encoder_inputs, sequence_length=input_length[0], dtype=tf.float32)\n",
    "    cell = tf.contrib.rnn.OutputProjectionWrapper(cell, frame_dim)\n",
    "    dec_outputs, dec_state = tf.contrib.legacy_seq2seq.rnn_decoder(decoder_inputs, enc_state, cell, loop_function=loopf)\n",
    "\n",
    "\n",
    "    # flatten the prediction and target to compute squared error loss\n",
    "    y_true = [tf.reshape(encoder_input, [-1]) for encoder_input in encoder_inputs]\n",
    "    y_pred = [tf.reshape(dec_output, [-1]) for dec_output in dec_outputs]\n",
    "\n",
    "    # Define loss and optimizer, minimize the squared error\n",
    "    loss = 0\n",
    "    for i in range(len(loss_inputs)):\n",
    "        loss += tf.reduce_sum(tf.square(tf.subtract(y_pred[i], y_true[len(loss_inputs) - i - 1])))\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    # Launch the graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Training cycle\n",
    "        input_datas = cPickle.load(open('./simulated_data/sim_normal_behavior_sequences','rb'))\n",
    "        trajectoryVecs = []\n",
    "        j = 0\n",
    "        for input_data in input_datas:\n",
    "            print ('Sample:')\n",
    "            print (j)\n",
    "            input_len = len(input_data)\n",
    "            print (input_len)\n",
    "            defalt = []\n",
    "            for i in range(0, frame_dim):\n",
    "                defalt.append(0)\n",
    "            while len(input_data) < max_n_steps:\n",
    "                input_data.append(defalt)\n",
    "            x = np.array(input_data)\n",
    "            print (np.shape(x[0]))\n",
    "            x = x.reshape((max_n_steps, batch_size, frame_dim))\n",
    "            embedding = None\n",
    "            for epoch in range(training_epochs):\n",
    "                feed = {seq_input: x, input_length: np.array([input_len])}\n",
    "                # Fit training using batch data\n",
    "                _, cost_value, embedding, en_int, de_outs, loss_in = sess.run(\n",
    "                    [optimizer, loss, enc_state, encoder_inputs, dec_outputs, loss_inputs], feed_dict=feed)\n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    print (\"logits\")\n",
    "                    a = sess.run(y_pred, feed_dict=feed)\n",
    "                    print (\"labels\")\n",
    "                    b = sess.run(y_true, feed_dict=feed)\n",
    "\n",
    "                    print(\"Epoch:\", '%04d' % (epoch + 1), \"cost=\", \"{:.9f}\".format(cost_value))\n",
    "            trajectoryVecs.append(embedding)\n",
    "            print(\"Optimization Finished!\")\n",
    "            j = j + 1\n",
    "        fout = open('./simulated_data/sim_traj_vec_normal_reverse', 'wb')\n",
    "        cPickle.dump(trajectoryVecs, fout)\n",
    "\n",
    "def vecClusterAnalysis():\n",
    "    print ('---------------------------------')\n",
    "    print ('Our Method')\n",
    "    trVecs = []\n",
    "    trs = cPickle.load(open('./simulated_data/sim_traj_vec_normal_reverse','rb'))\n",
    "    inte = []\n",
    "    for tr in trs:\n",
    "        trVecs.append(tr[0][0])\n",
    " \n",
    "  \n",
    "\n",
    "    \n",
    "    km = KMeans(n_clusters=3, random_state=2016)\n",
    "    clusters = km.fit(trVecs).labels_.tolist()\n",
    "    \n",
    "  \n",
    "   \n",
    "    \n",
    "    print(\"clusters\")\n",
    "    print(clusters)\n",
    "    all = 0.\n",
    "   \n",
    "    item = set(clusters[:sampleNum])\n",
    "    \n",
    "    print(item)\n",
    "    l = []\n",
    "    for i in item:\n",
    "        l.append([i,clusters[:sampleNum].count(i)])\n",
    "        \n",
    "        \n",
    "    print ('Straight:  '+ str(l))\n",
    "    m = max([te[1] for te in l])\n",
    "    all = all + m\n",
    "    print (float(m)/sampleNum)\n",
    "\n",
    "\n",
    "    m = 0.\n",
    "    item = set(clusters[sampleNum:sampleNum*2])\n",
    "    l = []\n",
    "    for i in item:\n",
    "        l.append([i,clusters[sampleNum:sampleNum*2].count(i)])\n",
    "    print ('Circling:  '+ str(l))\n",
    "    m = max([te[1] for te in l])\n",
    "    all = all + m\n",
    "    print (float(m)/sampleNum)\n",
    "\n",
    "    m = 0.\n",
    "    item = set(clusters[sampleNum*2:sampleNum*3])\n",
    "    l = []\n",
    "    for i in item:\n",
    "        l.append([i,clusters[sampleNum*2:sampleNum*3].count(i)])\n",
    "    m = max([te[1] for te in l])\n",
    "    print ('bending:   '+ str(l))\n",
    "    all = all + m\n",
    "    print (float(m)/sampleNum)\n",
    "    print ('overall')\n",
    "    print (all/(sampleNum*3))\n",
    "    print ('---------------------------------')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    completeTrajectories()\n",
    "    computeFeas()\n",
    "    generate_behavior_sequences()\n",
    "    generate_normal_behavior_sequence()\n",
    "    trajectory2Vec()\n",
    "    vecClusterAnalysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
