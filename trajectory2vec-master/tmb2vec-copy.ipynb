{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----1----\n",
      "----2----\n",
      "==generate_behavior_sequences=\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4355\n",
      "----ROLLING WINDOW--- 15\n",
      "15\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 3870\n",
      "----ROLLING WINDOW--- 13\n",
      "13\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4320\n",
      "----ROLLING WINDOW--- 15\n",
      "15\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4750\n",
      "----ROLLING WINDOW--- 16\n",
      "16\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4224\n",
      "----ROLLING WINDOW--- 15\n",
      "15\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4178\n",
      "----ROLLING WINDOW--- 14\n",
      "14\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4941\n",
      "----ROLLING WINDOW--- 17\n",
      "17\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4408\n",
      "----ROLLING WINDOW--- 15\n",
      "15\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 2939\n",
      "----ROLLING WINDOW--- 10\n",
      "10\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 3769\n",
      "----ROLLING WINDOW--- 13\n",
      "13\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 3790\n",
      "----ROLLING WINDOW--- 13\n",
      "13\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 3703\n",
      "----ROLLING WINDOW--- 13\n",
      "13\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4974\n",
      "----ROLLING WINDOW--- 17\n",
      "17\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4536\n",
      "----ROLLING WINDOW--- 16\n",
      "16\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4615\n",
      "----ROLLING WINDOW--- 16\n",
      "16\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4485\n",
      "----ROLLING WINDOW--- 15\n",
      "15\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 3658\n",
      "----ROLLING WINDOW--- 13\n",
      "13\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4809\n",
      "----ROLLING WINDOW--- 17\n",
      "17\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4374\n",
      "----ROLLING WINDOW--- 15\n",
      "15\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4425\n",
      "----ROLLING WINDOW--- 15\n",
      "15\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 2612\n",
      "----ROLLING WINDOW--- 9\n",
      "9\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 3918\n",
      "----ROLLING WINDOW--- 14\n",
      "14\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 2690\n",
      "----ROLLING WINDOW--- 9\n",
      "9\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4370\n",
      "----ROLLING WINDOW--- 15\n",
      "15\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 3779\n",
      "----ROLLING WINDOW--- 13\n",
      "13\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 2687\n",
      "----ROLLING WINDOW--- 9\n",
      "9\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 3722\n",
      "----ROLLING WINDOW--- 13\n",
      "13\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 4819\n",
      "----ROLLING WINDOW--- 17\n",
      "17\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 2609\n",
      "----ROLLING WINDOW--- 9\n",
      "9\n",
      "-time de l'avant derniere---ROLLING WINDOW--- 3955\n",
      "----ROLLING WINDOW--- 14\n",
      "14\n",
      "----3----\n",
      "(30,)\n",
      "15\n",
      "13\n",
      "15\n",
      "16\n",
      "15\n",
      "14\n",
      "17\n",
      "15\n",
      "10\n",
      "13\n",
      "13\n",
      "13\n",
      "17\n",
      "16\n",
      "16\n",
      "15\n",
      "13\n",
      "17\n",
      "15\n",
      "15\n",
      "9\n",
      "14\n",
      "9\n",
      "15\n",
      "13\n",
      "9\n",
      "13\n",
      "17\n",
      "9\n",
      "14\n",
      "415\n",
      "15\n",
      "13\n",
      "15\n",
      "16\n",
      "15\n",
      "14\n",
      "17\n",
      "15\n",
      "10\n",
      "13\n",
      "13\n",
      "13\n",
      "17\n",
      "16\n",
      "16\n",
      "15\n",
      "13\n",
      "17\n",
      "15\n",
      "15\n",
      "9\n",
      "14\n",
      "9\n",
      "15\n",
      "13\n",
      "9\n",
      "13\n",
      "17\n",
      "9\n",
      "14\n",
      "415\n",
      "(30,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable rnn/lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\HP-USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\HP-USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\HP-USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\HP-USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\HP-USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 1608, in variable_v2\n    shared_name=shared_name, name=name)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e8871d0b5c89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"----3----\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[0mgenerate_normal_behavior_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mtrajectory2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[0mvecClusterAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e8871d0b5c89>\u001b[0m in \u001b[0;36mtrajectory2Vec\u001b[1;34m()\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;31m# basic LSTM seq2seq model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_is_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_peepholes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_length\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m     \u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutputProjectionWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[0mdec_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloopf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mstatic_rnn\u001b[1;34m(cell, inputs, initial_state, dtype, sequence_length, scope)\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m             \u001b[0mcall_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcall_cell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m             state_size=cell.state_size)\n\u001b[0m\u001b[0;32m   1437\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_rnn_step\u001b[1;34m(time, sequence_length, min_sequence_length, max_sequence_length, zero_output, state, call_cell, state_size, skip_conditionals)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mempty_update\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;31m# otherwise calculation is required: copy some or all of it through\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         _maybe_copy_some_through)\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_output_and_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_zero_output\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[1;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[0;32m   1986\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1987\u001b[0m       \u001b[0mcontext_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1988\u001b[1;33m       \u001b[0morig_res_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildCondBranch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1989\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0morig_res_f\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1990\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"false_fn must have a return value.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildCondBranch\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m   1812\u001b[0m     \u001b[1;34m\"\"\"Add the subgraph defined by fn() to the graph.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1814\u001b[1;33m     \u001b[0moriginal_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1815\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpost_summaries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_summaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_maybe_copy_some_through\u001b[1;34m()\u001b[0m\n\u001b[0;32m    260\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_copy_some_through\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;34m\"\"\"Run RNN step.  Pass through either no or some past state.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m     \u001b[0mnew_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1423\u001b[0m         \u001b[0mvarscope\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreuse_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1424\u001b[0m       \u001b[1;31m# pylint: disable=cell-var-from-loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1425\u001b[1;33m       \u001b[0mcall_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1426\u001b[0m       \u001b[1;31m# pylint: enable=cell-var-from-loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1427\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;31m# method.  See the class docstring for more details.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     return base_layer.Layer.__call__(\n\u001b[1;32m--> 385\u001b[1;33m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m       \u001b[1;31m# Actually call layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m           \u001b[1;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1879\u001b[0m       \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1880\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1881\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1882\u001b[0m     \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1883\u001b[0m     \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(instance, input_shape)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, inputs_shape)\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_depth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m         partitioner=maybe_partitioner)\n\u001b[0m\u001b[0;32m    958\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m       \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_variable\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1482\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0madd_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m     \u001b[1;34m\"\"\"Alias for `add_weight`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[0mgetter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             **kwargs)\n\u001b[0m\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections_arg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         aggregation=aggregation)\n\u001b[0m\u001b[0;32m    385\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1494\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1237\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    560\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    512\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     synchronization, aggregation, trainable = (\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    862\u001b[0m         \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"tensorflow/python\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[1;32m--> 864\u001b[1;33m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    865\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable rnn/lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\HP-USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\HP-USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\HP-USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\HP-USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\HP-USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 1608, in variable_v2\n    shared_name=shared_name, name=name)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle as cPickle\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import *\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "random.seed(2016)\n",
    "sampleNum = 10\n",
    "\n",
    "def completeTrajectories():\n",
    "    simTrjss = cPickle.load(open('./simulated_data/sim_trajectories','rb'))\n",
    "    simTrjComps = []\n",
    "    for simTrjs in simTrjss:\n",
    "        trjsCom = []\n",
    "        for i in range(0,len(simTrjs)):\n",
    "            rec = []\n",
    "            if i==0:\n",
    "                # time, locationC, speedC, rotC\n",
    "                rec = [0,0,0,0]\n",
    "            else:\n",
    "                locC = math.sqrt((simTrjs[i][1]-simTrjs[i-1][1])**2+(simTrjs[i][2]-simTrjs[i-1][2])**2)\n",
    "                rec.append(simTrjs[i][0])\n",
    "                rec.append(locC)\n",
    "                rec.append(locC/(simTrjs[i][0]-simTrjs[i-1][0]))\n",
    "                rec.append(math.atan((simTrjs[i][2]-simTrjs[i-1][2])/ (simTrjs[i][1]-simTrjs[i-1][1])))\n",
    "            trjsCom.append(rec)\n",
    "        simTrjComps.append(trjsCom)\n",
    "    cPickle.dump(simTrjComps,open('./simulated_data/sim_trajectories_complete','wb'))\n",
    "    return simTrjComps\n",
    "\n",
    "def computeFeas():\n",
    "    simTrjCompss = cPickle.load(open('./simulated_data/sim_trajectories_complete','rb'))\n",
    "    simTrjFeas = []\n",
    "    for simTrjComps in simTrjCompss:\n",
    "        trjsComfea = []\n",
    "        for i in range(0,len(simTrjComps)):\n",
    "            rec = []\n",
    "            if i==0:\n",
    "                # time, locationC, speedC, rotC\n",
    "                rec = [0,0,0,0]\n",
    "            else:\n",
    "                locC = simTrjComps[i][1]\n",
    "                locCrate = locC/(simTrjComps[i][0]-simTrjComps[i-1][0])\n",
    "                rec.append(simTrjComps[i][0])\n",
    "                rec.append(locCrate)\n",
    "                if locCrate<3:\n",
    "                    rec.append(0)\n",
    "                    rec.append(0)\n",
    "                else:\n",
    "                    rec.append(simTrjComps[i][2]-simTrjComps[i-1][2])\n",
    "                    rec.append(simTrjComps[i][3]-simTrjComps[i-1][3])\n",
    "            trjsComfea.append(rec)\n",
    "        simTrjFeas.append(trjsComfea)\n",
    "    cPickle.dump(simTrjFeas, open('./simulated_data/sim_trajectories_feas', 'wb'))\n",
    "    return simTrjFeas\n",
    "\n",
    "def rolling_window(sample, windowsize = 600, offset = 300):\n",
    "    timeLength = sample[len(sample)-1][0]\n",
    "    print(\"-time de l'avant derniere---ROLLING WINDOW---\",timeLength)\n",
    "    windowLength = int (timeLength/offset)+1\n",
    "    print(\"----ROLLING WINDOW---\",windowLength)\n",
    "    windows = []\n",
    "    for i in range(0,windowLength):\n",
    "        windows.append([])\n",
    "\n",
    "    for record in sample:\n",
    "        time = record[0]\n",
    "        for i in range(0,windowLength):\n",
    "            if (time>(i*offset)) & (time<(i*offset+windowsize)):\n",
    "                windows[i].append(record)\n",
    "    \n",
    "    return windows\n",
    "    # pass\n",
    "\n",
    "def behavior_ext(windows):\n",
    "    behavior_sequence = []\n",
    "    for window in windows:\n",
    "        behaviorFeature = []\n",
    "        records = np.array(window)\n",
    "        if len(records) != 0:\n",
    "            # print np.shape(records)\n",
    "            pd = pandas.DataFrame(records)\n",
    "            pdd =  pd.describe()\n",
    "            #print(pdd)\n",
    "            # print pdd[1][0]\n",
    "            # for ii in range(1,4):\n",
    "            #     for jj in range(1,8):\n",
    "            #         behaviorFeature.append(pdd[ii][jj])\n",
    "            # behaviorFeature.append(pdd[0][1])\n",
    "            behaviorFeature.append(pdd[1][1])\n",
    "            behaviorFeature.append(pdd[2][1])\n",
    "            behaviorFeature.append(pdd[3][1])\n",
    "            # behaviorFeature.append(pdd[0][2])\n",
    "            # behaviorFeature.append(pdd[1][2])\n",
    "            # behaviorFeature.append(pdd[2][2])\n",
    "            # behaviorFeature.append(pdd[3][2])\n",
    "            # behaviorFeature.append(pdd[0][3])\n",
    "            behaviorFeature.append(pdd[1][3])\n",
    "            behaviorFeature.append(pdd[2][3])\n",
    "            behaviorFeature.append(pdd[3][3])\n",
    "            # behaviorFeature.append(pdd[0][4])\n",
    "            behaviorFeature.append(pdd[1][4])\n",
    "            behaviorFeature.append(pdd[2][4])\n",
    "            behaviorFeature.append(pdd[3][4])\n",
    "            # behaviorFeature.append(pdd[0][5])\n",
    "            behaviorFeature.append(pdd[1][5])\n",
    "            behaviorFeature.append(pdd[2][5])\n",
    "            behaviorFeature.append(pdd[3][5])\n",
    "            # behaviorFeature.append(pdd[0][6])\n",
    "            behaviorFeature.append(pdd[1][6])\n",
    "            behaviorFeature.append(pdd[2][6])\n",
    "            behaviorFeature.append(pdd[3][6])\n",
    "            # behaviorFeature.append(pdd[0][7])\n",
    "            behaviorFeature.append(pdd[1][7])\n",
    "            behaviorFeature.append(pdd[2][7])\n",
    "            behaviorFeature.append(pdd[3][7])\n",
    "\n",
    "            behavior_sequence.append(behaviorFeature)\n",
    "    return behavior_sequence\n",
    "\n",
    "def generate_behavior_sequences():\n",
    "    print(\"==generate_behavior_sequences=\")\n",
    "    f = open('./simulated_data/sim_trajectories_feas','rb')\n",
    "    sim_data = cPickle.load(f)\n",
    "    behavior_sequences = []\n",
    "\n",
    "    for sample in sim_data:\n",
    "        windows = rolling_window(sample)\n",
    "        behavior_sequence = behavior_ext(windows)\n",
    "        print(len(behavior_sequence))\n",
    "        behavior_sequences.append(behavior_sequence)\n",
    "    fout = open('./simulated_data/sim_behavior_sequences','wb')\n",
    "    #print(behavior_sequence)\n",
    "    cPickle.dump(behavior_sequences,fout)\n",
    "\n",
    "def generate_normal_behavior_sequence():\n",
    "    f = open('./simulated_data/sim_behavior_sequences','rb')\n",
    "    behavior_sequences = cPickle.load(f)\n",
    "\n",
    "    print(np.shape(behavior_sequences))\n",
    "    behavior_sequences_normal = []\n",
    "    templist = []\n",
    "    for item in behavior_sequences:\n",
    "        for ii in item:\n",
    "            templist.append(ii)\n",
    "        print (len(item))\n",
    "    print(len(templist))\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    # print np.shape(behavior_sequence)\n",
    "    templist_normal = min_max_scaler.fit_transform(templist).tolist()\n",
    "    index = 0\n",
    "    for item in behavior_sequences:\n",
    "        behavior_sequence_normal = []\n",
    "        for ii in item:\n",
    "            behavior_sequence_normal.append(templist_normal[index])\n",
    "            index = index + 1\n",
    "        print(len(behavior_sequence_normal))\n",
    "        behavior_sequences_normal.append(behavior_sequence_normal)\n",
    "    print(index)\n",
    "    print(np.shape(behavior_sequences_normal))\n",
    "    fout = open('./simulated_data/sim_normal_behavior_sequences', 'wb')\n",
    "    cPickle.dump(behavior_sequences_normal, fout)\n",
    "\n",
    "def trajectory2Vec():\n",
    "    def loopf(prev, i):\n",
    "        return prev\n",
    "\n",
    "    # Parameters\n",
    "    learning_rate = 0.0001\n",
    "    training_epochs = 300\n",
    "    display_step = 100\n",
    "\n",
    "    # Network Parameters\n",
    "    # the size of the hidden state for the lstm (notice the lstm uses 2x of this amount so actually lstm will have state of size 2)\n",
    "    size = 100\n",
    "    # 2 different sequences total\n",
    "    batch_size = 1\n",
    "    # the maximum steps for both sequences is 5\n",
    "    max_n_steps = 17\n",
    "    # each element/frame of the sequence has dimension of 3\n",
    "    frame_dim = 18\n",
    "\n",
    "    input_length = tf.placeholder(tf.int32)\n",
    "\n",
    "    initializer = tf.random_uniform_initializer(-1, 1)\n",
    "\n",
    "    # the sequences, has n steps of maximum size\n",
    "    # seq_input = tf.placeholder(tf.float32, [batch_size, max_n_steps, frame_dim])\n",
    "    seq_input = tf.placeholder(tf.float32, [max_n_steps, batch_size, frame_dim])\n",
    "    # what timesteps we want to stop at, notice it's different for each batch hence dimension of [batch]\n",
    "\n",
    "    # inputs for rnn needs to be a list, each item/frame being a timestep.\n",
    "    # we need to split our input into each timestep, and reshape it because split keeps dims by default\n",
    "    \n",
    "    useful_input = seq_input[0:input_length[0]]\n",
    "    loss_inputs = [tf.reshape(useful_input, [-1])]\n",
    "    encoder_inputs = [item for item in tf.unstack(seq_input)]\n",
    "    # if encoder input is \"X, Y, Z\", then decoder input is \"0, X, Y, Z\". Therefore, the decoder size\n",
    "    # and target size equal encoder size plus 1. For simplicity, here I droped the last one.\n",
    "    decoder_inputs = ([tf.zeros_like(encoder_inputs[0], name=\"GO\")] + encoder_inputs[:-1])\n",
    "    targets = encoder_inputs\n",
    "\n",
    "    # basic LSTM seq2seq model\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(size, state_is_tuple=True, use_peepholes=True)\n",
    "    outputs, enc_state = tf.contrib.rnn.static_rnn(cell, encoder_inputs, sequence_length=input_length[0], dtype=tf.float32)\n",
    "    cell = tf.nn.rnn_cell.OutputProjectionWrapper(cell, frame_dim)\n",
    "    dec_outputs, dec_state = tf.nn.seq2seq.rnn_decoder(decoder_inputs, enc_state, cell, loop_function=loopf)\n",
    "\n",
    "    # flatten the prediction and target to compute squared error loss\n",
    "    y_true = [tf.reshape(encoder_input, [-1]) for encoder_input in encoder_inputs]\n",
    "    y_pred = [tf.reshape(dec_output, [-1]) for dec_output in dec_outputs]\n",
    "\n",
    "    # Define loss and optimizer, minimize the squared error\n",
    "    loss = 0\n",
    "    for i in range(len(loss_inputs)):\n",
    "        loss += tf.reduce_sum(tf.square(tf.sub(y_pred[i], y_true[len(loss_inputs) - i - 1])))\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    # Launch the graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Training cycle\n",
    "        input_datas = cPickle.load(open('./simulated_data/sim_normal_behavior_sequences','rb'))\n",
    "        trajectoryVecs = []\n",
    "        j = 0\n",
    "        for input_data in input_datas:\n",
    "            print ('Sample:')\n",
    "            print (j)\n",
    "            input_len = len(input_data)\n",
    "            print (input_len)\n",
    "            defalt = []\n",
    "            for i in range(0, frame_dim):\n",
    "                defalt.append(0)\n",
    "            while len(input_data) < max_n_steps:\n",
    "                input_data.append(defalt)\n",
    "            x = np.array(input_data)\n",
    "            print (np.shape(x[0]))\n",
    "            x = x.reshape((max_n_steps, batch_size, frame_dim))\n",
    "            embedding = None\n",
    "            for epoch in range(training_epochs):\n",
    "                feed = {seq_input: x, input_length: np.array([input_len])}\n",
    "                # Fit training using batch data\n",
    "                _, cost_value, embedding, en_int, de_outs, loss_in = sess.run(\n",
    "                    [optimizer, loss, enc_state, encoder_inputs, dec_outputs, loss_inputs], feed_dict=feed)\n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    print (\"logits\")\n",
    "                    a = sess.run(y_pred, feed_dict=feed)\n",
    "                    print (\"labels\")\n",
    "                    b = sess.run(y_true, feed_dict=feed)\n",
    "\n",
    "                    print(\"Epoch:\", '%04d' % (epoch + 1), \"cost=\", \"{:.9f}\".format(cost_value))\n",
    "            trajectoryVecs.append(embedding)\n",
    "            print(\"Optimization Finished!\")\n",
    "            j = j + 1\n",
    "        fout = file('./simulated_data/sim_traj_vec_normal_reverse', 'wb')\n",
    "        cPickle.dump(trajectoryVecs, fout)\n",
    "\n",
    "def vecClusterAnalysis():\n",
    "    print ('---------------------------------')\n",
    "    print ('Our Method')\n",
    "    trVecs = []\n",
    "    trs = cPickle.load(open('./simulated_data/sim_traj_vec_normal_reverse','rb'))\n",
    "    inte = []\n",
    "    for tr in trs:\n",
    "        trVecs.append(tr[0][0])\n",
    "    km = KMeans(n_clusters=3, random_state=2016)\n",
    "    clusters = km.fit(trVecs).labels_.tolist()\n",
    "\n",
    "    all = 0.\n",
    "    item = set(clusters[:sampleNum])\n",
    "    l = []\n",
    "    for i in item:\n",
    "        l.append([i,clusters[:sampleNum].count(i)])\n",
    "    print ('Straight:  '+ str(l))\n",
    "    m = max([te[1] for te in l])\n",
    "    all = all + m\n",
    "    print (float(m)/sampleNum)\n",
    "\n",
    "\n",
    "    m = 0.\n",
    "    item = set(clusters[sampleNum:sampleNum*2])\n",
    "    l = []\n",
    "    for i in item:\n",
    "        l.append([i,clusters[sampleNum:sampleNum*2].count(i)])\n",
    "    print ('Circling:  '+ str(l))\n",
    "    m = max([te[1] for te in l])\n",
    "    all = all + m\n",
    "    print (float(m)/sampleNum)\n",
    "\n",
    "    m = 0.\n",
    "    item = set(clusters[sampleNum*2:sampleNum*3])\n",
    "    l = []\n",
    "    for i in item:\n",
    "        l.append([i,clusters[sampleNum*2:sampleNum*3].count(i)])\n",
    "    m = max([te[1] for te in l])\n",
    "    print ('bending:   '+ str(l))\n",
    "    all = all + m\n",
    "    print (float(m)/sampleNum)\n",
    "    print ('overall')\n",
    "    print (all/(sampleNum*3))\n",
    "    print ('---------------------------------')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    completeTrajectories()\n",
    "    print(\"----1----\")\n",
    "    computeFeas()\n",
    "    print(\"----2----\")\n",
    "    generate_behavior_sequences()\n",
    "    print(\"----3----\")\n",
    "    generate_normal_behavior_sequence()\n",
    "    trajectory2Vec()\n",
    "    vecClusterAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
